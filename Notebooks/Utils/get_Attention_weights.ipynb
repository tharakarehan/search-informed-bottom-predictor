{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1237QWD1_vUnxOfSNMjL04teaC06lYUHJ","authorship_tag":"ABX9TyOgBueHMl/uJq3SKHTnMb4i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# install required packages (only need to run once)\n","!pip install pytorch-lightning pytorch-forecasting"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDOfSlzNDNMV","executionInfo":{"status":"ok","timestamp":1751919224961,"user_tz":-330,"elapsed":111023,"user":{"displayName":"Tharaka Rehan","userId":"11459857212930492604"}},"outputId":"ebc762aa-c98b-4f51-f40c-466868bc3582"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n","Collecting pytorch-forecasting\n","  Downloading pytorch_forecasting-1.4.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.14.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.0.2)\n","Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n","  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.15.3)\n","Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.2.2)\n","Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.6.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n","Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_forecasting-1.4.0-py3-none-any.whl (260 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning-2.5.2-py3-none-any.whl (821 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning, pytorch-forecasting\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-2.5.2 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-forecasting-1.4.0 pytorch-lightning-2.5.2 torchmetrics-1.7.4\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"i6-z6VDL_Q_W","executionInfo":{"status":"ok","timestamp":1751919691118,"user_tz":-330,"elapsed":7,"user":{"displayName":"Tharaka Rehan","userId":"11459857212930492604"}}},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","import pytorch_lightning as pl\n","from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n","from lightning.pytorch import Trainer\n","\n","from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n","from pytorch_forecasting.data import GroupNormalizer\n","from pytorch_forecasting.metrics import RMSE\n","import torchmetrics\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n","# Monkey-patch CUDA availability checks to always be False\n","torch.cuda.is_available = lambda: False\n","torch.cuda.device_count = lambda: 0\n","\n","\n","def get_attention_weights(\n","    model: TemporalFusionTransformer,\n","    input_data: np.ndarray or torch.Tensor,\n","    prediction_length: int = 1,\n","    max_encoder_length: int = 32,\n","):\n","    \"\"\"\n","    Extracts encoder and decoder attention weights from a saved TFT model.\n","\n","    Parameters:\n","        model: a loaded TemporalFusionTransformer\n","        input_data: numpy array or torch tensor of shape (1, max_encoder_length, num_features)\n","        prediction_length: number of future steps the model predicts\n","        max_encoder_length: number of past steps used for encoding\n","    Returns:\n","        encoder_attention: Tensor of shape (batch=1, num_heads, time, time)\n","        decoder_attention: Tensor of shape (batch=1, num_heads, time, time)\n","    \"\"\"\n","    # model.eval()\n","    # convert numpy to tensor if needed and ensure float32\n","    if isinstance(input_data, np.ndarray):\n","        x_cont_encoder = torch.from_numpy(input_data).float()\n","    else:\n","        x_cont_encoder = input_data.float()\n","    # verify shape\n","    assert x_cont_encoder.ndim == 3 and x_cont_encoder.size(1) == max_encoder_length, \\\n","        f\"Expected input_data shape (1, {max_encoder_length}, num_features), got {tuple(x_cont_encoder.shape)}\"\n","\n","    # prepare decoder continuous inputs as zeros\n","    num_features = x_cont_encoder.size(2)\n","    x_cont_decoder = torch.zeros((1, prediction_length, num_features), dtype=torch.float32)\n","\n","    n_static_cat = len(getattr(model.hparams, \"static_categoricals\", []))\n","    n_static_real = len(getattr(model.hparams, \"static_reals\", []))\n","    n_time_known_cat = len(getattr(model.hparams, \"time_varying_known_categoricals\", []))\n","    n_time_unknown_cat = len(getattr(model.hparams, \"time_varying_unknown_categoricals\", []))\n","    n_time_cat = n_time_known_cat + n_time_unknown_cat\n","\n","    # 4) zero‐fill your cats\n","    x_static_cat   = torch.zeros((1, n_static_cat), dtype=torch.long)\n","    x_static_real  = torch.zeros((1, len(model.hparams.static_reals)))\n","    x_encoder_cat  = torch.zeros((1, max_encoder_length, n_time_cat), dtype=torch.long)\n","    x_decoder_cat  = torch.zeros((1, prediction_length, n_time_cat), dtype=torch.long)\n","\n","    # build input dict for TFT forward\n","    x = {\n","        \"static_cat\":   x_static_cat,\n","        \"static_real\":  x_static_real,\n","        \"encoder_cat\":  x_encoder_cat,\n","        \"decoder_cat\":  x_decoder_cat,\n","        \"encoder_cont\": x_cont_encoder,\n","        \"decoder_cont\": x_cont_decoder,\n","        \"encoder_lengths\": torch.tensor([max_encoder_length]),\n","        \"decoder_lengths\": torch.tensor([prediction_length]),\n","        \"target_scale\": torch.ones((1, 1, 1)),\n","    }\n","    with torch.no_grad():\n","        out = model(x)\n","    return out.get(\"encoder_attention\"), out.get(\"decoder_attention\")\n","\n","\n","import torch\n","from pytorch_forecasting import TemporalFusionTransformer\n","\n","def load_tft_strict_cpu(checkpoint_path: str) -> TemporalFusionTransformer:\n","    \"\"\"\n","    Load a TFT Lightning checkpoint strictly on CPU.\n","    Avoids any .cpu() calls that trigger torchmetrics CUDA init.\n","    \"\"\"\n","    # 1) Load full checkpoint (allow unpickle) onto CPU\n","    ckpt = torch.load(\n","        checkpoint_path,\n","        map_location=torch.device(\"cpu\"),\n","        weights_only=False\n","    )\n","    # 2) Extract Lightning hyperparameters\n","    hparams = ckpt.get(\"hyper_parameters\", ckpt.get(\"hparams\", {}))\n","    # 3) Instantiate fresh TFT on CPU (no GPUs involved)\n","    model = TemporalFusionTransformer(**hparams)\n","    # 4) Load weights & buffers (already on CPU)\n","    model.load_state_dict(ckpt[\"state_dict\"])\n","    # 5) Patch every torchmetrics.Metric to live on CPU\n","    for module in model.modules():\n","        if isinstance(module, torchmetrics.Metric):\n","            module._device = torch.device(\"cpu\")\n","    # 6) Set to inference mode (no further .cpu needed)\n","    model.eval()\n","    return model"]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/tft/data/df_pca_n.csv')"],"metadata":{"id":"56GYc5jX_wEk","executionInfo":{"status":"ok","timestamp":1751919270464,"user_tz":-330,"elapsed":7425,"user":{"displayName":"Tharaka Rehan","userId":"11459857212930492604"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"E32sBAuYC-t8","executionInfo":{"status":"ok","timestamp":1751919271563,"user_tz":-330,"elapsed":109,"user":{"displayName":"Tharaka Rehan","userId":"11459857212930492604"}},"outputId":"98bd8fdc-794c-4193-808d-b2569647f042"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            pca1      pca2      pca3      pca4      pca5      pca6      pca7  \\\n","0      -4.728898 -1.115874 -0.350434  0.465851  0.346966 -0.063788 -0.840479   \n","1      -4.635488 -2.741018  1.690103 -2.328273 -0.770616  1.601905  0.038216   \n","2      -4.694583 -1.193204  0.440777  1.554080  0.044771  0.620009  0.986779   \n","3      -4.708888 -2.340780  0.054083 -0.864007  0.050861 -0.809183 -2.061673   \n","4      -4.715028 -1.494159  0.141522  1.021576  0.024130  0.061481  0.593962   \n","...          ...       ...       ...       ...       ...       ...       ...   \n","210480  5.715374  2.329135 -1.077321  0.317249  0.370631 -0.451116  0.247526   \n","210481  5.719356  2.395326 -1.081455 -0.022791  0.384120  0.969201  1.308615   \n","210482  5.710340  1.108185 -1.326260 -1.562592  0.287421  1.651703  1.574665   \n","210483  5.704047  0.310273 -1.231921 -1.317224  0.126251 -1.785598 -1.010372   \n","210484  5.657368  0.198007 -1.478933 -0.306594  0.129324 -0.762598  0.848717   \n","\n","            pca8     pca11     pca13     pca14     pca16     pca17     pca18  \\\n","0      -0.644939  0.120015  1.910322  1.305534  0.669070  0.307071  1.389222   \n","1      -1.187851  1.623920  0.795812 -1.426525  1.030457  0.065907  1.300028   \n","2       0.868953  1.621704 -0.432284  0.463382  0.740617  0.691632  1.340005   \n","3       0.437444  1.108165  0.823587  0.540933  0.793279  0.287486  1.366688   \n","4      -0.776617  1.957156  0.502589  1.086233  0.736398  0.540106  1.357617   \n","...          ...       ...       ...       ...       ...       ...       ...   \n","210480 -2.197046 -0.225612 -0.190178  0.455132  0.526352 -0.586859 -0.757855   \n","210481 -1.453685 -0.851483 -0.207386  0.093235  0.253536 -0.464944 -0.765870   \n","210482 -0.300371  1.421647 -1.088612  0.157923  0.380004 -0.325366 -0.754873   \n","210483 -0.279763  1.316855  0.653663  0.165989  0.261319  0.163953 -0.790322   \n","210484  0.690108 -0.245311  1.251140  0.678558 -0.068743  0.568296 -0.789649   \n","\n","           pca19     pca20     pca21     close  \n","0       1.563639  0.564337  0.155247  28212.73  \n","1       1.824407 -0.132587  0.037102  28127.82  \n","2       1.675177  0.299795  0.201588  28169.00  \n","3       1.618464  0.438763  0.133583  28128.59  \n","4       1.638440  0.410520  0.196583  28150.00  \n","...          ...       ...       ...       ...  \n","210480 -2.109945 -0.840042  0.248779  94360.00  \n","210481 -2.096844 -0.825267  0.472029  94408.05  \n","210482 -2.078163 -0.854962  0.357805  94276.00  \n","210483 -2.071569 -0.848133  0.353897  94159.83  \n","210484 -2.030318 -0.921498  0.479895  94144.18  \n","\n","[210485 rows x 18 columns]"],"text/html":["\n","  <div id=\"df-ee029ea3-9dc1-48bc-ab62-66d80755d88c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pca1</th>\n","      <th>pca2</th>\n","      <th>pca3</th>\n","      <th>pca4</th>\n","      <th>pca5</th>\n","      <th>pca6</th>\n","      <th>pca7</th>\n","      <th>pca8</th>\n","      <th>pca11</th>\n","      <th>pca13</th>\n","      <th>pca14</th>\n","      <th>pca16</th>\n","      <th>pca17</th>\n","      <th>pca18</th>\n","      <th>pca19</th>\n","      <th>pca20</th>\n","      <th>pca21</th>\n","      <th>close</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-4.728898</td>\n","      <td>-1.115874</td>\n","      <td>-0.350434</td>\n","      <td>0.465851</td>\n","      <td>0.346966</td>\n","      <td>-0.063788</td>\n","      <td>-0.840479</td>\n","      <td>-0.644939</td>\n","      <td>0.120015</td>\n","      <td>1.910322</td>\n","      <td>1.305534</td>\n","      <td>0.669070</td>\n","      <td>0.307071</td>\n","      <td>1.389222</td>\n","      <td>1.563639</td>\n","      <td>0.564337</td>\n","      <td>0.155247</td>\n","      <td>28212.73</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-4.635488</td>\n","      <td>-2.741018</td>\n","      <td>1.690103</td>\n","      <td>-2.328273</td>\n","      <td>-0.770616</td>\n","      <td>1.601905</td>\n","      <td>0.038216</td>\n","      <td>-1.187851</td>\n","      <td>1.623920</td>\n","      <td>0.795812</td>\n","      <td>-1.426525</td>\n","      <td>1.030457</td>\n","      <td>0.065907</td>\n","      <td>1.300028</td>\n","      <td>1.824407</td>\n","      <td>-0.132587</td>\n","      <td>0.037102</td>\n","      <td>28127.82</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-4.694583</td>\n","      <td>-1.193204</td>\n","      <td>0.440777</td>\n","      <td>1.554080</td>\n","      <td>0.044771</td>\n","      <td>0.620009</td>\n","      <td>0.986779</td>\n","      <td>0.868953</td>\n","      <td>1.621704</td>\n","      <td>-0.432284</td>\n","      <td>0.463382</td>\n","      <td>0.740617</td>\n","      <td>0.691632</td>\n","      <td>1.340005</td>\n","      <td>1.675177</td>\n","      <td>0.299795</td>\n","      <td>0.201588</td>\n","      <td>28169.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-4.708888</td>\n","      <td>-2.340780</td>\n","      <td>0.054083</td>\n","      <td>-0.864007</td>\n","      <td>0.050861</td>\n","      <td>-0.809183</td>\n","      <td>-2.061673</td>\n","      <td>0.437444</td>\n","      <td>1.108165</td>\n","      <td>0.823587</td>\n","      <td>0.540933</td>\n","      <td>0.793279</td>\n","      <td>0.287486</td>\n","      <td>1.366688</td>\n","      <td>1.618464</td>\n","      <td>0.438763</td>\n","      <td>0.133583</td>\n","      <td>28128.59</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-4.715028</td>\n","      <td>-1.494159</td>\n","      <td>0.141522</td>\n","      <td>1.021576</td>\n","      <td>0.024130</td>\n","      <td>0.061481</td>\n","      <td>0.593962</td>\n","      <td>-0.776617</td>\n","      <td>1.957156</td>\n","      <td>0.502589</td>\n","      <td>1.086233</td>\n","      <td>0.736398</td>\n","      <td>0.540106</td>\n","      <td>1.357617</td>\n","      <td>1.638440</td>\n","      <td>0.410520</td>\n","      <td>0.196583</td>\n","      <td>28150.00</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>210480</th>\n","      <td>5.715374</td>\n","      <td>2.329135</td>\n","      <td>-1.077321</td>\n","      <td>0.317249</td>\n","      <td>0.370631</td>\n","      <td>-0.451116</td>\n","      <td>0.247526</td>\n","      <td>-2.197046</td>\n","      <td>-0.225612</td>\n","      <td>-0.190178</td>\n","      <td>0.455132</td>\n","      <td>0.526352</td>\n","      <td>-0.586859</td>\n","      <td>-0.757855</td>\n","      <td>-2.109945</td>\n","      <td>-0.840042</td>\n","      <td>0.248779</td>\n","      <td>94360.00</td>\n","    </tr>\n","    <tr>\n","      <th>210481</th>\n","      <td>5.719356</td>\n","      <td>2.395326</td>\n","      <td>-1.081455</td>\n","      <td>-0.022791</td>\n","      <td>0.384120</td>\n","      <td>0.969201</td>\n","      <td>1.308615</td>\n","      <td>-1.453685</td>\n","      <td>-0.851483</td>\n","      <td>-0.207386</td>\n","      <td>0.093235</td>\n","      <td>0.253536</td>\n","      <td>-0.464944</td>\n","      <td>-0.765870</td>\n","      <td>-2.096844</td>\n","      <td>-0.825267</td>\n","      <td>0.472029</td>\n","      <td>94408.05</td>\n","    </tr>\n","    <tr>\n","      <th>210482</th>\n","      <td>5.710340</td>\n","      <td>1.108185</td>\n","      <td>-1.326260</td>\n","      <td>-1.562592</td>\n","      <td>0.287421</td>\n","      <td>1.651703</td>\n","      <td>1.574665</td>\n","      <td>-0.300371</td>\n","      <td>1.421647</td>\n","      <td>-1.088612</td>\n","      <td>0.157923</td>\n","      <td>0.380004</td>\n","      <td>-0.325366</td>\n","      <td>-0.754873</td>\n","      <td>-2.078163</td>\n","      <td>-0.854962</td>\n","      <td>0.357805</td>\n","      <td>94276.00</td>\n","    </tr>\n","    <tr>\n","      <th>210483</th>\n","      <td>5.704047</td>\n","      <td>0.310273</td>\n","      <td>-1.231921</td>\n","      <td>-1.317224</td>\n","      <td>0.126251</td>\n","      <td>-1.785598</td>\n","      <td>-1.010372</td>\n","      <td>-0.279763</td>\n","      <td>1.316855</td>\n","      <td>0.653663</td>\n","      <td>0.165989</td>\n","      <td>0.261319</td>\n","      <td>0.163953</td>\n","      <td>-0.790322</td>\n","      <td>-2.071569</td>\n","      <td>-0.848133</td>\n","      <td>0.353897</td>\n","      <td>94159.83</td>\n","    </tr>\n","    <tr>\n","      <th>210484</th>\n","      <td>5.657368</td>\n","      <td>0.198007</td>\n","      <td>-1.478933</td>\n","      <td>-0.306594</td>\n","      <td>0.129324</td>\n","      <td>-0.762598</td>\n","      <td>0.848717</td>\n","      <td>0.690108</td>\n","      <td>-0.245311</td>\n","      <td>1.251140</td>\n","      <td>0.678558</td>\n","      <td>-0.068743</td>\n","      <td>0.568296</td>\n","      <td>-0.789649</td>\n","      <td>-2.030318</td>\n","      <td>-0.921498</td>\n","      <td>0.479895</td>\n","      <td>94144.18</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>210485 rows × 18 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee029ea3-9dc1-48bc-ab62-66d80755d88c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ee029ea3-9dc1-48bc-ab62-66d80755d88c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ee029ea3-9dc1-48bc-ab62-66d80755d88c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-bacab501-9c35-4357-8e61-e7b05437459e\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bacab501-9c35-4357-8e61-e7b05437459e')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-bacab501-9c35-4357-8e61-e7b05437459e button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_bff4a7b4-c145-467c-a9de-3147386f762a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_bff4a7b4-c145-467c-a9de-3147386f762a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["look_back = 32\n","pred_len = 1\n","# Alternatively, load an existing checkpoint directly:\n","ckpt_path = \"/content/drive/MyDrive/tft/models/best_tft.ckpt\"\n","loaded_model = load_tft_strict_cpu(ckpt_path)\n","print(f\"Loaded model from {ckpt_path}\")\n","\n","# prepare a sample window\n","feature_cols = [col for col in df.columns if col not in [\"time_idx\", \"series\", \"close\"]]\n","window = df[feature_cols].iloc[-look_back:].to_numpy()[None, :, :]\n","input_tensor = torch.from_numpy(window)\n","\n","# extract attention weights\n","enc_attn, dec_attn = get_attention_weights(\n","    loaded_model,\n","    input_tensor,\n","    prediction_length=pred_len,\n","    max_encoder_length=look_back\n",")\n","\n","print(f\"Encoder attention shape: {enc_attn.shape}\")\n","print(f\"Decoder attention shape: {dec_attn.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"id":"SL5b-nuIF8RE","executionInfo":{"status":"error","timestamp":1751919696093,"user_tz":-330,"elapsed":483,"user":{"displayName":"Tharaka Rehan","userId":"11459857212930492604"}},"outputId":"149bc44c-a4d7-496a-eeec-e06a3d6e5f7b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n","/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded model from /content/drive/MyDrive/tft/models/best_tft.ckpt\n"]},{"output_type":"error","ename":"IndexError","evalue":"index 0 is out of bounds for dimension 1 with size 0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-7-2398458984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# extract attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m enc_attn, dec_attn = get_attention_weights(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-6-1259316747.py\u001b[0m in \u001b[0;36mget_attention_weights\u001b[0;34m(model, input_data, prediction_length, max_encoder_length)\u001b[0m\n\u001b[1;32m     76\u001b[0m     }\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder_attention\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoder_attention\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/models/temporal_fusion_transformer/_tft.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# encode + decode length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mmax_encoder_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         \u001b[0minput_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         input_vectors.update(\n\u001b[1;32m    539\u001b[0m             {\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/models/nn/embeddings.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 )\n\u001b[1;32m    212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0minput_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_categoricals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_output\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# concatenate output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 1 with size 0"]}]}]}